# -*- coding: utf-8 -*-
"""student_depression_dataset_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fJLTqiWw69-upHZQBxBEWCMz6u4LpkAL

# ğŸ§  **Ã–ÄŸrenci Depresyonu Tahmin Projesi**
### ğŸ“ Ã–ÄŸrenciler ArasÄ±nda Ruh SaÄŸlÄ±ÄŸÄ± EÄŸilimlerinin ve Etkileyen FaktÃ¶rlerin Analizi

## ğŸ“Œ Projenin AmacÄ±:
Bu proje Ã¼niversite Ã¶ÄŸrencileri arasÄ±nda gÃ¶rÃ¼len depresyon dÃ¼zeylerini analiz etmeyi ve tahmin etmeyi amaÃ§lamaktadÄ±r.

AmaÃ§; depresyona sebep olabilecek demografik, akademik ve yaÅŸam tarzÄ± faktÃ¶rlerini inceleyerek riskli bireyleri Ã¶nceden belirleyebilmektir.

Proje; psikoloji, eÄŸitim ve veri bilimi gibi disiplinler arasÄ± Ã§alÄ±ÅŸmalara katkÄ± sunabilecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## ğŸ“ Veri Setinin Ã–zellikleri:
- **Veri FormatÄ±:** CSV (her satÄ±r bir Ã¶ÄŸrenciye ait bilgileri iÃ§erir)
- **TanÄ±mlayÄ±cÄ± Bilgi:** Ã–ÄŸrenci ID'si (her birey iÃ§in eÅŸsiz)
- **Demografik Bilgiler:** YaÅŸ, Cinsiyet, Ä°kamet Åehri
- **Akademik Bilgiler:** Genel Not OrtalamasÄ± (CGPA), Akademik BaskÄ±, Ã‡alÄ±ÅŸma BiÃ§imi
- **YaÅŸam TarzÄ± FaktÃ¶rleri:** Uyku sÃ¼resi, beslenme dÃ¼zeni, Ã§alÄ±ÅŸma saati, iÅŸ memnuniyeti
- **Psikolojik ve Sosyal Etkenler:** Ailede ruhsal hastalÄ±k geÃ§miÅŸi, finansal stres, intihar dÃ¼ÅŸÃ¼ncesi geÃ§miÅŸi

Bu aÃ§Ä±klamalar veri setini ve projenin baÄŸlamÄ±nÄ± daha aÃ§Ä±k ve akademik bir dille sunar.

# Hedef DeÄŸiÅŸken:
- Depression_Status: Bir Ã¶ÄŸrencinin depresyon yaÅŸayÄ±p yaÅŸamadÄ±ÄŸÄ±nÄ± gÃ¶steren ikili gÃ¶sterge (0/1 veya Evet/HayÄ±r)

---

# 1. AdÄ±m: KÃ¼tÃ¼phanelerin YÃ¼klenmesi ve Veri Setinin OkunmasÄ±

Bu adÄ±mda gerekli Python kÃ¼tÃ¼phaneleri yÃ¼klÃ¼yoruz ve veri setine genel bir bakÄ±ÅŸ yapÄ±yoruz.
"""

# Commented out IPython magic to ensure Python compatibility.
# Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenmesi.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import scipy.stats as stats
import plotly.express as px
import warnings
import joblib

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score

from xgboost import XGBClassifier

# TÃ¼m uyarÄ±larÄ± gÃ¶rmezden gelmek iÃ§in kullanÄ±lÄ±r. Kodun Ã§Ä±ktÄ±sÄ±nÄ± daha temiz hale getirir.
warnings.filterwarnings('ignore')

#Seaborn grafiklerinin stilini ayarlar.
sns.set(style="whitegrid")
# %matplotlib inline

"""- pandas: Veri manipÃ¼lasyonu ve analizi iÃ§in.
- numpy: SayÄ±sal iÅŸlemler iÃ§in.
- matplotlib.pyplot: Temel veri gÃ¶rselleÅŸtirme iÃ§in.
- seaborn: Ä°statistiksel veri gÃ¶rselleÅŸtirme iÃ§in.
- re: DÃ¼zenli ifadeler (regular expressions) iÃ§in.
- scipy.stats: Ä°statistiksel testler iÃ§in.
- sklearn.model_selection: Makine Ã¶ÄŸrenimi modellerini eÄŸitmek ve deÄŸerlendirmek iÃ§in.
- sklearn.preprocessing: Veri Ã¶niÅŸleme iÃ§in.
- sklearn.linear_model: Lojistik regresyon modeli iÃ§in.
- sklearn.ensemble: Rastgele orman (Random Forest) modeli iÃ§in.
- sklearn.metrics: Model performansÄ±nÄ± deÄŸerlendirmek iÃ§in.
- plotly.express: EtkileÅŸimli gÃ¶rselleÅŸtirmeler iÃ§in.
- warnings: UyarÄ±larÄ± yÃ¶netmek iÃ§in.
"""

# CSV dosyasÄ±nÄ± bir Pandas DataFrame'ine atama.
df = pd.read_csv("/content/student_depression_dataset.csv")

# DataFrame'in ilk 5 satÄ±rÄ±nÄ± yazdÄ±rÄ±r. Veri setinin iÃ§eriÄŸine hÄ±zlÄ±ca gÃ¶z atmayÄ± saÄŸlar.
print("ğŸ”¹ Ä°lk 5 satÄ±r:")
df.head()

# Veri yapÄ±sÄ±nÄ± ve eksik deÄŸerleri kontrol et
print("\nğŸ”¹ Veri Seti Ã–zeti:")

from prettytable import PrettyTable

# Veri setindeki her sÃ¼tunun adÄ±nÄ±, kaÃ§ tane boÅŸ olmayan deÄŸer iÃ§erdiÄŸini ve veri tipini yazdÄ±rÄ±r. Bu iÅŸlem veri setinin genel yapÄ±sÄ±nÄ± anlamak iÃ§in Ã¶nemlidir.
def pretty_info(df):
    table = PrettyTable()
    table.field_names = ["Column", "Non-Null Count", "Dtype"]

    for col in df.columns:
        non_null_count = df[col].count()
        dtype = df[col].dtype
        table.add_row([col, non_null_count, dtype])

    print(table)

pretty_info(df)

# DataFrame'in boyutlarÄ±nÄ± (satÄ±r ve sÃ¼tun sayÄ±sÄ±nÄ±) yazdÄ±rÄ±r.
print("\nğŸ”¹ Veri Seti Boyutu:")
df.shape

"""prettytable ile tablo biÃ§iminde veri yapÄ±sÄ± gÃ¶sterimi saÄŸlandÄ±.

Veri seti: 27901 gÃ¶zlem, 18 Ã¶zellik iÃ§eriyor.
"""

# DataFrame'deki sayÄ±sal sÃ¼tunlarÄ±n temel istatistiklerini (ortalama, standart sapma, min, max, vb.) ve kategorik sÃ¼tunlarÄ±n frekans bilgilerini yazdÄ±rÄ±r.
# Bu iÅŸlem veri setinin daÄŸÄ±lÄ±mÄ± ve Ã¶zetlenmesi iÃ§in kullanÄ±lÄ±r.
print("\nğŸ”¹ Temel Ä°statistikler:")
df.describe(include='all')

"""# 2. AdÄ±m: Veri Ã–n Ä°ÅŸleme ve Eksik Veri Kontrolleri

Bu adÄ±mda veri setindeki sÃ¼tunlarÄ±n veri tipleri dÃ¼zenlenir, bazÄ± sÃ¼tunlardaki deÄŸerler temizlenir ve eksik veri kontrolÃ¼ yapÄ±lÄ±r.
"""

# 'Depression' sÃ¼tununu integer veri tipine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Bu iÅŸlem sÃ¼tunun sayÄ±sal iÅŸlemler iÃ§in uygun olmasÄ±nÄ± saÄŸlar.
df['Depression'] = df['Depression'].astype(int)


# Kategorik olarak ele alÄ±nmasÄ± gereken sÃ¼tunlarÄ±n bir listesini tanÄ±mlar.
cat_cols = ['Gender', 'City', 'Profession', 'Degree',
            'Have you ever had suicidal thoughts ?',
            'Family History of Mental Illness']

# YukarÄ±da tanÄ±mlanan sÃ¼tunlarÄ± 'category' veri tipine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Bu iÅŸlem bellek kullanÄ±mÄ±nÄ± optimize eder ve bazÄ± analizler iÃ§in gereklidir.
for col in cat_cols:
    df[col] = df[col].astype('category')

# Bu sÃ¼tunlardaki benzersiz deÄŸerleri yazdÄ±rÄ±r. Bu iÅŸlem sÃ¼tunlarÄ±n iÃ§eriÄŸini anlamak ve temizlik stratejileri belirlemek iÃ§in Ã¶nemlidir.
print("Unique values in 'Sleep Duration':", df['Sleep Duration'].unique())
print("Unique values in 'Financial Stress':", df['Financial Stress'].unique())

"""'Depression' sÃ¼tunu sayÄ±sal hale getirilerek model eÄŸitimi iÃ§in hazÄ±rlanÄ±yor.

astype('category') kullanÄ±mÄ±, bu sÃ¼tunlardaki verilerin sÄ±nÄ±f (kategori) olarak algÄ±lanmasÄ±nÄ± saÄŸlar.

Bu iÅŸlem bellek kullanÄ±mÄ± ve model performansÄ± aÃ§Ä±sÄ±ndan Ã¶nemlidir.

unique() komutlarÄ± sayesinde sÃ¼tunlarda tutarsÄ±z veya temizlenmesi gereken deÄŸerler olup olmadÄ±ÄŸÄ± kontrol edilir.
"""

# 'Sleep Duration' sÃ¼tunundaki metinlerden sayÄ±sal saat deÄŸerlerini Ã§Ä±karmak iÃ§in dÃ¼zenli ifadeler kullanÄ±r. Bu iÅŸlem sÃ¼tundaki veriyi analiz edilebilir hale getirir.
def extract_hours(s):
    # Bir sayÄ± bulma (decimal deÄŸerler dahil)
    match = re.search(r"(\d+(\.\d+)?)", str(s))
    return float(match.group(1)) if match else np.nan

df['Sleep Duration'] = df['Sleep Duration'].apply(extract_hours)

# 'Financial Stress' sÃ¼tununu 'category' veri tipine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
df['Financial Stress'] = df['Financial Stress'].astype('category')

# DeÄŸiÅŸikliklerin doÄŸru yapÄ±ldÄ±ÄŸÄ±nÄ± doÄŸrulamak iÃ§in bu sÃ¼tunlarÄ±n ilk birkaÃ§ satÄ±rÄ±nÄ± yazdÄ±rÄ±r.
print(df[['Sleep Duration', 'Financial Stress']].head())

"""extract_hours fonksiyonu, Ã¶rneÄŸin "5-6 hours" gibi metinlerden 5.0 deÄŸerini Ã§Ä±karÄ±r.

Bu dÃ¶nÃ¼ÅŸÃ¼m, uyku sÃ¼resi Ã¼zerinde sayÄ±sal analiz ve gÃ¶rselleÅŸtirme yapabilmemizi saÄŸlar.

'Financial Stress' sÃ¼tunu daha Ã¶nce sayÄ±sal gibi gÃ¶rÃ¼nse de aslÄ±nda sÄ±nÄ±fsal bir bilgi (1â€“5 gibi), bu nedenle kategorik yapÄ±lmasÄ± daha anlamlÄ±.
"""

# Her sÃ¼tundaki eksik deÄŸerlerin sayÄ±sÄ±nÄ± hesaplar.
missing_values = df.isnull().sum()
print("Missing values:\n", missing_values)

"""Bu adÄ±m veri temizliÄŸi iÃ§in temel oluÅŸturur.

Eksik veri tespiti modelin doÄŸruluÄŸunu doÄŸrudan etkileyebilir.

Ã–rneÄŸin, Sleep Duration sÃ¼tununda 18 eksik deÄŸer olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.
"""

# 'Sleep Duration' sÃ¼tunundaki eksik deÄŸerleri sÃ¼tunun medyanÄ± ile doldurur. Medyan, aykÄ±rÄ± deÄŸerlerden etkilenmediÄŸi iÃ§in tercih edilir.
for col in ['Sleep Duration']:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].median(), inplace=True)

"""Ortalama yerine medyanÄ±n kullanÄ±lmasÄ± uÃ§ deÄŸerlerden etkilenmemek iÃ§in tercih edilir.

inplace=True ile veri seti yerinde deÄŸiÅŸtirilir.

---

# AdÄ±m 3: KeÅŸifsel Veri Analizi (EDA)

Bu adÄ±mda veri setindeki deÄŸiÅŸkenlerin daÄŸÄ±lÄ±mlarÄ± ve iliÅŸkileri gÃ¶rselleÅŸtirilir ardÄ±ndan buna baÄŸlÄ± olarak analiz edilir.

---

## 3.1 Hedef DeÄŸiÅŸkenin DaÄŸÄ±lÄ±mÄ± (Depression)
"""

# 'Depression' sÃ¼tunundaki deÄŸerlerin (0 ve 1) sayÄ±sÄ±nÄ± gÃ¶steren bir Ã§ubuk grafik oluÅŸturur. Bu iÅŸlem depresyon durumunun veri setindeki daÄŸÄ±lÄ±mÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r.
plt.figure(figsize=(8,5))
sns.countplot(x='Depression', data=df, palette="viridis")
plt.title("Depresyonun Ã–ÄŸrenciler ArasÄ±ndaki DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Depresyon (0 = HayÄ±r, 1 = Evet)")
plt.ylabel("Miktar")
plt.show()

"""---
# ğŸ“Š Grafik Analizi: Depresyonun Ã–ÄŸrenciler ArasÄ±ndaki DaÄŸÄ±lÄ±mÄ±

## ğŸ” Grafikte Ne GÃ¶steriliyor?
Bu grafik veri setindeki Ã¶ÄŸrencilerin depresyon durumuna gÃ¶re (0: HayÄ±r, 1: Evet) daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶stermektedir.

Yatay eksende (x) depresyon durumu (Depresyon sÃ¼tunu) yer alÄ±yor:

0 = Depresyonda deÄŸil

1 = Depresyonda

Dikey eksende (y) ise her sÄ±nÄ±fa ait gÃ¶zlem (kiÅŸi) sayÄ±sÄ±, yani frekans gÃ¶steriliyor.

Miktar etiketi ile gÃ¶sterilen deÄŸerler yaklaÅŸÄ±k olarak:

0 (Depresyonda olmayanlar): 11.500 civarÄ±

1 (Depresyonda olanlar): 16.300 civarÄ±

## ğŸ“Œ Yorum:
Veri setinde depresyonda olduÄŸunu belirten Ã¶ÄŸrencilerin sayÄ±sÄ± depresyonda olmayanlardan belirgin ÅŸekilde fazla.

Bu daÄŸÄ±lÄ±m dengesiz bir sÄ±nÄ±f yapÄ±sÄ±na iÅŸaret eder.

---

# 3.2 Kategorik DeÄŸiÅŸkenlerin Analizi:
"""

# Cinsiyet ve depresyon durumu arasÄ±ndaki iliÅŸkiyi gÃ¶steren bir gruplanmÄ±ÅŸ Ã§ubuk grafik oluÅŸturur. Bu iÅŸlem depresyonun cinsiyete gÃ¶re nasÄ±l deÄŸiÅŸtiÄŸini anlamak iÃ§in kullanÄ±lÄ±r.
plt.figure(figsize=(8,5))
sns.countplot(x='Gender', hue='Depression', data=df, palette="Set2")
plt.title("Cinsiyete GÃ¶re Depresyon DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Cinsiyet")
plt.ylabel("Miktar")
plt.legend(title="Depresyon")
plt.show()

"""---
#ğŸ“Š Grafik Analizi: Cinsiyete GÃ¶re Depresyon DaÄŸÄ±lÄ±mÄ±
##ğŸ” Grafikte Ne GÃ¶steriliyor?
Grafik, Ã¶ÄŸrencilerin cinsiyetlerine gÃ¶re depresyon durumlarÄ±nÄ± gruplandÄ±rarak gÃ¶steriyor.

x ekseni: Cinsiyet (Female, Male)

y ekseni: Ã–ÄŸrenci sayÄ±sÄ± (frekans)

Renkler:

YeÅŸil ton (Depresyon = 0): Depresyonda olmayanlar

Turuncu ton (Depresyon = 1): Depresyonda olanlar

##ğŸ“Œ Yorum:
Her iki cinsiyette de depresyonda olan birey sayÄ±sÄ±, olmayanlardan fazla.

Ancak:

Erkek Ã¶ÄŸrencilerde depresyonda olan birey sayÄ±sÄ±, depresyonda olmayanlardan Ã§ok daha yÃ¼ksek (yaklaÅŸÄ±k 9000 vs 6400).

KadÄ±n Ã¶ÄŸrencilerde depresyon daÄŸÄ±lÄ±mÄ± daha dengeli (yaklaÅŸÄ±k 7200 depresyonda vs 5200 deÄŸil).

Bu durum veri setinde depresyonun erkeklerde daha yaygÄ±n gÃ¶zlemlendiÄŸini gÃ¶steriyor olabilir.

---

# 3.3 SayÄ±sal DeÄŸiÅŸkenlerin DaÄŸÄ±lÄ±mÄ±:
"""

# Belirtilen sayÄ±sal sÃ¼tunlarÄ±n her biri iÃ§in histogramlar oluÅŸturur. Bu iÅŸlem her bir deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r.
num_features = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',
                'Study Satisfaction', 'Job Satisfaction', 'Sleep Duration', 'Work/Study Hours']
df[num_features].hist(bins=20, figsize=(15,10))
plt.tight_layout()
plt.show()

"""---
# ğŸ“Š Grafik Seti Analizi: SayÄ±sal DeÄŸiÅŸkenlerin DaÄŸÄ±lÄ±mlarÄ±
##1ï¸âƒ£ Age (YaÅŸ)
YaÅŸ daÄŸÄ±lÄ±mÄ± 18â€“35 aralÄ±ÄŸÄ±nda yoÄŸunlaÅŸmÄ±ÅŸ.

En Ã§ok veri 19â€“21 yaÅŸ grubunda.

YaÅŸ arttÄ±kÃ§a katÄ±lÄ±mcÄ± sayÄ±sÄ± azalÄ±yor, bu da Ã¼niversite Ã¶ÄŸrencisi profiline uygun.

##2ï¸âƒ£ Academic Pressure (Akademik BaskÄ±)
1â€“5 arasÄ±nda derecelendirilmiÅŸ.

En Ã§ok 3 seviyesi verilmiÅŸ (ortalama dÃ¼zeyde baskÄ±).

4 ve 5 de yÃ¼ksek sayÄ±da, bu da birÃ§ok Ã¶ÄŸrencinin yÃ¼ksek baskÄ± altÄ±nda olduÄŸunu gÃ¶steriyor.

##3ï¸âƒ£ Work Pressure (Ä°ÅŸ BaskÄ±sÄ±)
Neredeyse tÃ¼m deÄŸerler 0.

Bu, bÃ¼yÃ¼k olasÄ±lÄ±kla Ã¶ÄŸrencilerin bÃ¼yÃ¼k kÄ±smÄ±nÄ±n Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± ya da veride Ã§ok az iÅŸ baskÄ±sÄ± bildirildiÄŸini gÃ¶sterir.

Veride dengesizlik veya anlamlÄ±lÄ±k sorunu olabilir.

##4ï¸âƒ£ CGPA (Genel Not OrtalamasÄ±)
DeÄŸerler 5.5 â€“ 10 arasÄ±nda.

En yoÄŸun grup 6.0â€“6.5 aralÄ±ÄŸÄ±nda.

Notlar genel olarak orta ve Ã¼zeri seviyede.

##5ï¸âƒ£ Study Satisfaction (Ã‡alÄ±ÅŸma Memnuniyeti)
1â€“5 aralÄ±ÄŸÄ±nda.

2, 3 ve 4 seviyelerinde yoÄŸunluk var.

En az memnuniyet â€œ5â€te gÃ¶rÃ¼nÃ¼yor, bu biraz ÅŸaÅŸÄ±rtÄ±cÄ± olabilir.

##6ï¸âƒ£ Job Satisfaction (Ä°ÅŸ Memnuniyeti)
TamamÄ± 0 deÄŸeri. Bu, veride:

Ya bu sÃ¼tun yanlÄ±ÅŸ toplanmÄ±ÅŸ olabilir,

Ya da Ã§oÄŸu Ã¶ÄŸrenci Ã§alÄ±ÅŸmadÄ±ÄŸÄ± iÃ§in hiÃ§ veri giriÅŸi olmamÄ±ÅŸ.

Modelleme iÃ§in anlamsÄ±z olabilir, Ã§Ä±karÄ±labilir.

##7ï¸âƒ£ Sleep Duration (Uyku SÃ¼resi)
Sadece 3 belirgin seviye: 5, 7, 8 saat.

5 saatlik uyku aÃ§Ä±k farkla Ã¶nde (yaklaÅŸÄ±k 14.000 kiÅŸi).

Bu, Ã¶ÄŸrencilerin Ã§oÄŸunun az uyuduÄŸunu gÃ¶sterir ve depresyon ile iliÅŸkilendirilebilir.

##8ï¸âƒ£ Work/Study Hours (Ã‡alÄ±ÅŸma/Ders Ã‡alÄ±ÅŸma Saatleri)
0â€“12 saat aralÄ±ÄŸÄ±nda.

En Ã§ok 10â€“12 saatlik yoÄŸun Ã§alÄ±ÅŸma grubu var.

0â€“4 saat bandÄ±nda da kayda deÄŸer katÄ±lÄ±mcÄ± var.

##âœ… Genel DeÄŸerlendirme:
Work Pressure ve Job Satisfaction deÄŸiÅŸkenleri veri bakÄ±mÄ±ndan zayÄ±f. Analiz dÄ±ÅŸÄ± bÄ±rakÄ±labilir.

Age, CGPA, Sleep Duration, Work/Study Hours gibi deÄŸiÅŸkenler modellemeye katkÄ± saÄŸlayabilecek seviyede bilgi taÅŸÄ±yor.

Uyku sÃ¼resi ve akademik baskÄ± gibi deÄŸiÅŸkenlerin depresyonla iliÅŸkisi ayrÄ±ca test edilmelidir.

---

# 3.4 Korelasyon Analizi:
"""

# Belirtilen sayÄ±sal sÃ¼tunlar arasÄ±ndaki korelasyon matrisini hesaplar.
plt.figure(figsize=(10,8))
num_cols = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',
            'Study Satisfaction', 'Job Satisfaction', 'Sleep Duration', 'Work/Study Hours']
corr_matrix = df[num_cols].corr()

# Korelasyon matrisini bir Ä±sÄ± haritasÄ± olarak gÃ¶rselleÅŸtirir. Bu iÅŸlem deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkilerin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ anlamak iÃ§in kullanÄ±lÄ±r.
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Korelasyon IsÄ± HaritasÄ±")
plt.show()

"""---
#ğŸ“Š Grafik Analizi: Korelasyon IsÄ± HaritasÄ±
##ğŸ” Ne GÃ¶steriyor?
Grafik, deÄŸiÅŸken Ã§iftleri arasÄ±ndaki Pearson korelasyon katsayÄ±sÄ±nÄ± gÃ¶steriyor.

Renk skalasÄ±:

KÄ±rmÄ±zÄ±ya yakÄ±n renkler: Pozitif korelasyon (0.0 â†’ +1.0)

Maviye yakÄ±n renkler: Negatif korelasyon (0.0 â†’ -1.0)

Beyaz/soluk renkler: Korelasyon yok veya Ã§ok dÃ¼ÅŸÃ¼k

##ğŸ“Œ Dikkat Ã‡eken Bulgular:
âœ… En YÃ¼ksek Pozitif Korelasyonlar:
Work Pressure â†” Job Satisfaction: 0.77

Bu oldukÃ§a yÃ¼ksek bir korelasyon.

Bu iki sÃ¼tun muhtemelen aynÄ± kaynaktan otomatik olarak 0 olarak girilmiÅŸti; bu nedenle veri kalitesi ÅŸÃ¼pheli olabilir.

AynÄ± zamanda job satisfaction sÃ¼tunu daha Ã¶nce de sadece 0 deÄŸerindeydi, yani anlamlÄ± bilgi taÅŸÄ±mÄ±yor.

##ğŸ§Š Negatif veya ZayÄ±f Korelasyonlar:
TÃ¼m diÄŸer iliÅŸkiler zayÄ±f:

Academic Pressure â†” Study Satisfaction: -0.11

Akademik baskÄ± arttÄ±kÃ§a Ã§alÄ±ÅŸma memnuniyeti biraz azalÄ±yor olabilir.

Age â†” Academic Pressure: -0.08

YaÅŸ arttÄ±kÃ§a akademik baskÄ± hissi biraz azalÄ±yor olabilir.

##âš ï¸ Neredeyse HiÃ§ Korelasyon Olmayanlar:
CGPA, Sleep Duration, Work/Study Hours gibi deÄŸiÅŸkenlerin hemen hemen tÃ¼m diÄŸer sÃ¼tunlarla korelasyon deÄŸeri |0.00 â€“ 0.05| aralÄ±ÄŸÄ±nda.

Bu, bu deÄŸiÅŸkenlerin birbirlerinden baÄŸÄ±msÄ±z deÄŸiÅŸkenler olduÄŸunu gÃ¶sterir.

##ğŸ§  Yorum:
DeÄŸiÅŸkenler arasÄ±nda genel olarak gÃ¼Ã§lÃ¼ doÄŸrusal iliÅŸkiler bulunmuyor.

Bu, modellemeye baÅŸlarken:

Multicollinearity (Ã§oklu doÄŸrusal iliÅŸki) sorununun dÃ¼ÅŸÃ¼k olduÄŸu anlamÄ±na gelir (iyi bir ÅŸey).

Ancak bu aynÄ± zamanda modelin gÃ¼Ã§lÃ¼ tahminler yapmasÄ± iÃ§in daha fazla karmaÅŸÄ±k etkileÅŸim (interaction) gerekebileceÄŸini gÃ¶sterir.

---

# 3.5 Plotly ile GeliÅŸmiÅŸ GÃ¶rselleÅŸtirme:
"""

# CGPA ve Ã‡alÄ±ÅŸma Memnuniyeti arasÄ±ndaki iliÅŸkiyi gÃ¶steren etkileÅŸimli bir saÃ§Ä±lÄ±m grafiÄŸi oluÅŸturur.
# Depresyon durumuna gÃ¶re renklendirir ve ek bilgiler (yaÅŸ, cinsiyet, akademik baskÄ±) saÄŸlar.

fig = px.scatter(df, x="CGPA", y="Study Satisfaction", color="Depression",
                 hover_data=['Age', 'Gender', 'Academic Pressure'],
                 title="Depresyona GÃ¶re CGPA ve EÄŸitim Memnuniyeti")
fig.show()

"""---

# ğŸ“Š Grafik Analizi: Depresyona GÃ¶re CGPA ve EÄŸitim Memnuniyeti
##ğŸ” Ne GÃ¶steriyor?
X ekseni: CGPA (Genel Not OrtalamasÄ±)

Y ekseni: Study Satisfaction (EÄŸitim/Ã‡alÄ±ÅŸma Memnuniyeti), 0 ile 5 arasÄ± derecelendirilmiÅŸ

Renk: Depresyon durumu (0 = depresyonda deÄŸil, 1 = depresyonda)

SarÄ±: Depresyonda olan Ã¶ÄŸrenciler

Mor: Depresyonda olmayan Ã¶ÄŸrenciler

Aradaki renk tonlarÄ± ise gÃ¶rselde arada kalan yumuÅŸak geÃ§iÅŸli olasÄ±lÄ±k gibi gÃ¶rÃ¼nÃ¼r ancak bu durumda bÃ¼yÃ¼k ihtimalle sadece 0 ve 1 deÄŸerleri var, yani iki sÄ±nÄ±f.

##ğŸ“Œ Yorumlar:
###1ï¸âƒ£ Genel DaÄŸÄ±lÄ±m:
Ã‡oÄŸu Ã¶ÄŸrenci 6.0 ile 9.5 CGPA arasÄ±nda yoÄŸunlaÅŸmÄ±ÅŸ.

EÄŸitim memnuniyeti aÃ§Ä±sÄ±ndan en fazla veri seviye 3â€“4 civarÄ±nda.

Ã‡alÄ±ÅŸma memnuniyeti dÃ¼ÅŸÃ¼k olanlarda da, yÃ¼ksek olanlarda da depresyon vakalarÄ± gÃ¶zlemleniyor.

###2ï¸âƒ£ Depresyon Rengine GÃ¶re DeÄŸerlendirme:
TÃ¼m CGPA seviyelerinde depresyonda olan bireyler (sarÄ±) var.

Yani not ortalamasÄ± yÃ¼ksek olanlar da depresyonda olabilir.

DolayÄ±sÄ±yla CGPA ile depresyon arasÄ±nda gÃ¼Ã§lÃ¼ bir iliÅŸki gÃ¶zlemlenmiyor.

Study Satisfaction deÄŸeri 0â€“1 olan bireylerde depresyon (sarÄ±) Ã§ok yaygÄ±n.

Bu, Ã§alÄ±ÅŸma memnuniyetinin dÃ¼ÅŸÃ¼k olmasÄ±nÄ±n depresyonla gÃ¼Ã§lÃ¼ bir iliÅŸkiye sahip olabileceÄŸini gÃ¶steriyor.

---

# AdÄ±m 4: Ä°statistiksel Analiz

Bu adÄ±mda akademik baskÄ± ile depresyon arasÄ±ndaki iliÅŸkiyi istatistiksel olarak test etmek iÃ§in hipotez testleri uygulanÄ±r.


---

# 4.1 Hipotez Testi (Akademik BaskÄ± ve Depresyon)
"""

# Veri setini depresyonu olan ve olmayan Ã¶ÄŸrencilere gÃ¶re iki gruba ayÄ±rÄ±r.
group_dep = df[df['Depression'] == 1]['Academic Pressure']
group_non_dep = df[df['Depression'] == 0]['Academic Pressure']

# Her iki grubun boyutunu yazdÄ±rÄ±r. Ä°statistiksel testlerin uygulanabilirliÄŸi iÃ§in grup boyutlarÄ± Ã¶nemlidir.
print("Depresyonda olan grup bÃ¼yÃ¼klÃ¼ÄŸÃ¼:", len(group_dep))
print("Depresyonda olmayan grup bÃ¼yÃ¼klÃ¼ÄŸÃ¼:", len(group_non_dep))

# Her iki grupta da yeterli sayÄ±da gÃ¶zlem varsa (en az 3) testleri uygular.
if len(group_dep) >= 3 and len(group_non_dep) >= 3:
    # Ä°ki baÄŸÄ±msÄ±z grup arasÄ±ndaki ortalama farkÄ± test etmek iÃ§in t-testi uygular.
    t_stat, p_val = stats.ttest_ind(group_dep, group_non_dep)
    print("T-test istatistiÄŸi: {:.3f}, p-value: {:.3f}".format(t_stat, p_val))

    # Ä°ki baÄŸÄ±msÄ±z grup arasÄ±ndaki daÄŸÄ±lÄ±m farkÄ±nÄ± test etmek iÃ§in Mann-Whitney U testini uygular (non-parametrik test).
    u_stat, p_val_u = stats.mannwhitneyu(group_dep, group_non_dep)
    print("Mann-Whitney U test istatistiÄŸi: {:.3f}, p-value: {:.3f}".format(u_stat, p_val_u))
else:
    print("Gruplardan biri istatistiksel test iÃ§in yeterli gÃ¶zlem sayÄ±sÄ±na sahip deÄŸildir.")

"""Test sonuÃ§larÄ± (t-istatistiÄŸi, p-deÄŸeri, U-istatistiÄŸi, p-deÄŸeri) yazdÄ±rÄ±lÄ±r. P-deÄŸeri, hipotezin (gruplar arasÄ±nda fark yok) doÄŸru olma olasÄ±lÄ±ÄŸÄ±nÄ± gÃ¶sterir. DÃ¼ÅŸÃ¼k bir p-deÄŸeri (genellikle < 0.05) hipotezin reddedilmesi gerektiÄŸini gÃ¶sterir.

---

# AdÄ±m 5: Veri TanÄ±mlayÄ±cÄ±sÄ± Ã‡oÄŸaltma

Bu adÄ±mda yeni Ã¶zellikler oluÅŸturulur ve kategorik deÄŸiÅŸkenler Ã¼retilir.

---

# 5.1 BileÅŸik Ã–zellikler OluÅŸturma
Ã–rneÄŸin; Akademik ve Ä°ÅŸ BaskÄ±sÄ±nÄ± â€œToplam BaskÄ±â€ metriÄŸinde birleÅŸtirelim.
"""

# 'Academic Pressure' ve 'Work Pressure' sÃ¼tunlarÄ±nÄ± toplayarak 'Total Pressure' adÄ±nda yeni bir sÃ¼tun oluÅŸturur. Bu iÅŸlem toplam baskÄ± dÃ¼zeyini temsil eder.
df['Total Pressure'] = df['Academic Pressure'] + df['Work Pressure']

plt.figure(figsize=(8,5))
sns.boxplot(x='Depression', y='Total Pressure', data=df, palette="coolwarm")
plt.title("Depresyon Durumuna GÃ¶re Toplam BaskÄ±")
plt.xlabel("Depresyon (0 = No, 1 = Yes)")
plt.ylabel("Toplam BaskÄ±")
plt.show()

"""# ğŸ“Š Ne GÃ¶steriyor Bu Grafik?
Bu grafik Total Pressure (Toplam BaskÄ±) deÄŸiÅŸkeninin, depresyon durumu (0 = HayÄ±r, 1 = Evet) deÄŸiÅŸkenine gÃ¶re nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

## ğŸ” Grafik Ãœzerinden Teknik Yorum:
| Grup                  | Ortalama/Medyan       | BaskÄ± DÃ¼zeyi          | YayÄ±lÄ±m                  |
| --------------------- | --------------------- | --------------------- | ------------------------ |
| **0 (Depresyon yok)** | Medyan yaklaÅŸÄ±k **2** | **Daha dÃ¼ÅŸÃ¼k baskÄ±**  | GeniÅŸ yayÄ±lÄ±m 0â€“5 arasÄ± |
| **1 (Depresyon var)** | Medyan yaklaÅŸÄ±k **4** | **Daha yÃ¼ksek baskÄ±** | BÃ¼yÃ¼k kÄ±smÄ± 3â€“5 arasÄ±    |


##ğŸ§  Ã–nemli GÃ¶zlemler:
- Depresyonda olmayan kiÅŸiler genellikle 0â€“3 toplam baskÄ± dÃ¼zeyine sahip.
- Depresyonda olanlar genellikle 3â€“5 aralÄ±ÄŸÄ±nda daha yÃ¼ksek baskÄ±ya sahip.
- Her iki grup iÃ§in de aykÄ±rÄ± deÄŸerler gÃ¶zÃ¼kmÃ¼yor â†’ veriler dÃ¼zgÃ¼n daÄŸÄ±lmÄ±ÅŸ.
- Medyanlar arasÄ±nda ciddi fark var â†’ bu deÄŸiÅŸken depresyonla iliÅŸkili olabilir.



---

# AdÄ±m 6: Kategorik DeÄŸiÅŸkenlerin Ä°Ã§in Encoding

Makine Ã¶ÄŸrenimi iÃ§in sayÄ±sal Ã¶zelliklere ihtiyacÄ±mÄ±z vardÄ±r. SÄ±ralÄ± olmayan kategorik deÄŸiÅŸkenler iÃ§in one-hot kodlamasÄ±nÄ± kullanabiliriz. Basit olmasÄ± iÃ§in burada birkaÃ§ Ã¶nemli Ã¶zelliÄŸi kodlayacaÄŸÄ±z.
"""

# Encoding iÅŸlemi uygulanmasÄ± gereken kategorik sÃ¼tunlarÄ±n bir listesini tanÄ±mlar.
cat_features = ['Gender', 'City', 'Profession', 'Degree',
                'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness', 'Financial Stress']

# Belirtilen kategorik sÃ¼tunlarÄ± one-hot encoding kullanarak sayÄ±sal sÃ¼tunlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)

df_encoded.head()

"""---


# AdÄ±m 7: Makine Ã–ÄŸrenimi Modeli OluÅŸturma

Bu Ã§alÄ±ÅŸma Ã¶zelinde 5 farklÄ± model oluÅŸturacaÄŸÄ±z:
- Logistic Regression
- Decision Tree
- Random Forest
- Random Forest + XGBoost
- KNN



---

## 7.1 Verileri Modelleme iÃ§in HazÄ±rlama

Ã–zellikleri (X) ve hedefi (y) tanÄ±mlayÄ±n. SayÄ±sal Ã¶zelliklerin bir alt kÃ¼mesini ve kodlanmÄ±ÅŸ kategorik Ã¶zellikleri kullanÄ±rÄ±z.
"""

# DataFrame'den istenmeyen sÃ¼tunlarÄ± kaldÄ±r
# Ã‡Ä±karÄ±lacak sÃ¼tunlarÄ±n listesi
drop_cols = ['id', 'Depression', 'Have you ever had suicidal thoughts ?',
             'Family History of Mental Illness', 'Gender', 'City',
             'Profession', 'Degree', 'Financial Stress']
# Belirtilen sÃ¼tunlarÄ± Ã§Ä±kararak yeni bir DataFrame oluÅŸtur
df_clean = df.drop(columns=drop_cols)

# Kategorik sÃ¼tunlarÄ± one-hot coding ile sayÄ±sal hale getir
df_encoded = pd.get_dummies(df_clean, drop_first=True)

# Encoding iÅŸleminden sonraki sÃ¼tunlarÄ± yazdÄ±r (hata ayÄ±klama iÃ§in)
print("Encoding sonrasÄ± sÃ¼tunlar:", df_encoded.columns.tolist())

# Encoding uygulanan orijinal kategorik sÃ¼tunlarÄ±n anahtarlarÄ±nÄ± tanÄ±mla
cat_keys = ["Have you ever had suicidal thoughts ?", "Family History of Mental Illness",
            "Gender", "City", "Profession", "Degree", "Financial Stress"]

# Orijinal kategorik sÃ¼tunlardan tÃ¼retilen kukla (dummy) sÃ¼tunlarÄ± belirle
dummy_cols = [col for col in df_encoded.columns if any(key in col for key in cat_keys)]

# Ã‡Ä±karÄ±lacak sÃ¼tunlarÄ±n listesini oluÅŸtur
drop_cols = []
for col in ['id', 'Depression']:  # 'id' ve 'Depression' sÃ¼tunlarÄ±nÄ± kontrol et
    if col in df_encoded.columns:  # EÄŸer sÃ¼tun varsa
        drop_cols.append(col)  # Listeye ekle
drop_cols += dummy_cols  # Kukla sÃ¼tunlarÄ± Ã§Ä±karÄ±lacaklar listesine ekle

# Belirlenen sÃ¼tunlarÄ± Ã§Ä±kararak Ã¶zellik matrisini oluÅŸtur
X = df_encoded.drop(columns=drop_cols)
if 'Depression' in df_encoded.columns:  # EÄŸer 'Depression' sÃ¼tunu hala varsa
    y = df_encoded['Depression']  # Hedef deÄŸiÅŸkeni kodlanmÄ±ÅŸ veriden al
else:
    y = df['Depression']  # Yoksa orijinal veriden al


# SayÄ±sal Ã¶zellikleri standartlaÅŸtÄ±rÄ±n
from sklearn.preprocessing import StandardScaler  # StandardScaler'Ä± iÃ§e aktar
scaler = StandardScaler()  # StandardScaler nesnesi oluÅŸtur
num_feats = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',
            'Study Satisfaction', 'Job Satisfaction', 'Sleep Duration',
            'Work/Study Hours', 'Total Pressure']  # StandartlaÅŸtÄ±rÄ±lacak sayÄ±sal sÃ¼tunlarÄ± seÃ§
X[num_feats] = scaler.fit_transform(X[num_feats])  # SayÄ±sal sÃ¼tunlarÄ± standartlaÅŸtÄ±r

print("Ã–zellik matrisi boyutu:", X.shape)  # Ã–zellik matrisinin boyutunu yazdÄ±r

"""

---


## 7.2 Verileri EÄŸitim ve Test KÃ¼melerine AyÄ±rma"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""---

## 7.3 Logistic Regression Model
"""

# Logistic Regression
log_model = LogisticRegression(max_iter=1000)  # Lojistik Regresyon modelini 1000 maksimum iterasyon ile oluÅŸtur
log_model.fit(X_train, y_train)  # Modeli eÄŸitim verileri (X_train, y_train) ile eÄŸit

# Predictions and evaluation
y_pred_log = log_model.predict(X_test)  # EÄŸitilmiÅŸ modeli kullanarak test verileri (X_test) Ã¼zerinde tahmin yap
print("Logistic Regression Classification Report:")  # Lojistik Regresyon sÄ±nÄ±flandÄ±rma raporunu yazdÄ±r
print(classification_report(y_test, y_pred_log))  # GerÃ§ek test etiketleri (y_test) ve tahmin edilen etiketler (y_pred_log) kullanarak sÄ±nÄ±flandÄ±rma raporunu oluÅŸtur ve yazdÄ±r

# Confusion matrix
cm_log = confusion_matrix(y_test, y_pred_log)  # GerÃ§ek ve tahmin edilen etiketler arasÄ±ndaki karÄ±ÅŸÄ±klÄ±k matrisini oluÅŸtur
sns.heatmap(cm_log, annot=True, fmt="d", cmap='Blues')  # KarÄ±ÅŸÄ±klÄ±k matrisini bir Ä±sÄ± haritasÄ± olarak gÃ¶rselleÅŸtir (annot=True: deÄŸerleri gÃ¶ster, fmt="d": tam sayÄ± formatÄ±nda gÃ¶ster, cmap='Blues': mavi renk paleti kullan)
plt.title("Logistic Regression Confusion Matrix")  # GrafiÄŸe baÅŸlÄ±k ekle
plt.xlabel("Predicted")  # X eksenine "Tahmin Edilen" etiketini ekle
plt.ylabel("Actual")  # Y eksenine "GerÃ§ek" etiketini ekle
plt.show()  # GrafiÄŸi gÃ¶ster

# ROC Curve
y_prob_log = log_model.predict_proba(X_test)[:, 1]  # Test verileri iÃ§in sÄ±nÄ±f 1 olasÄ±lÄ±klarÄ±nÄ± al
fpr, tpr, thresholds = roc_curve(y_test, y_prob_log)  # GerÃ§ek etiketler ve olasÄ±lÄ±klar kullanarak ROC eÄŸrisi iÃ§in yanlÄ±ÅŸ pozitif oranÄ± (fpr), gerÃ§ek pozitif oranÄ± (tpr) ve eÅŸikleri hesapla
roc_auc_log = auc(fpr, tpr)  # AUC (EÄŸri AltÄ±ndaki Alan) deÄŸerini hesapla
plt.figure(figsize=(8, 6))  # Yeni bir figÃ¼r oluÅŸtur
plt.plot(fpr, tpr, label=f'Logistic Regression ROC curve (AUC = {roc_auc_log:.2f})', color='darkorange')  # ROC eÄŸrisini Ã§iz ve AUC deÄŸerini etikete ekle
plt.plot([0, 1], [0, 1], 'k--')  # Rastgele tahmin Ã§izgisini (45 derece) Ã§iz
plt.xlabel('False Positive Rate')  # X eksenine "YanlÄ±ÅŸ Pozitif OranÄ±" etiketini ekle
plt.ylabel('True Positive Rate')  # Y eksenine "GerÃ§ek Pozitif OranÄ±" etiketini ekle
plt.title('ROC Curve - Logistic Regression')  # GrafiÄŸe baÅŸlÄ±k ekle
plt.legend(loc="lower right")  # Legendi saÄŸ alt kÃ¶ÅŸeye yerleÅŸtir
plt.show()  # GrafiÄŸi gÃ¶ster

joblib.dump(log_model, "logistic_regression_model.pkl")
joblib.dump(X_train.columns.tolist(), "logistic_regression_model_feature_names.pkl")

"""---
# ğŸ“Œ Logistic Regression Matrix HakkÄ±nda Yorum:

Logistic Regression modeli, depresyonlu bireyleri belirlemede baÅŸarÄ±lÄ± bir performans gÃ¶stermektedir.

Toplamda 2677 depresyonlu birey doÄŸru ÅŸekilde tahmin edilmiÅŸ, 561 kiÅŸi ise gÃ¶zden kaÃ§Ä±rÄ±lmÄ±ÅŸtÄ±r. Buna karÅŸÄ±n, 722 saÄŸlÄ±klÄ± birey hatalÄ± ÅŸekilde depresyonlu olarak etiketlenmiÅŸtir.

Model depresyonu saptama oranÄ± (recall) aÃ§Ä±sÄ±ndan gÃ¼Ã§lÃ¼dÃ¼r (%82.7) ancak yanlÄ±ÅŸ pozitif oranÄ± az da olsa dikkat gerektirir.

---



# ğŸ“Œ ROC Curve - Logistic Regression HakkÄ±nda Yorum:
ROC eÄŸrisine gÃ¶re Logistic Regression modeli depresyonlu ve depresyonsuz bireyleri ayÄ±rmada gÃ¼Ã§lÃ¼ bir performans sergilemektedir.

AUC = 0.84 deÄŸeri modelin yanlÄ±ÅŸ pozitif oranÄ±nÄ± dÃ¼ÅŸÃ¼k tutarken doÄŸru pozitif oranÄ±nÄ± yÃ¼ksek tutabildiÄŸini gÃ¶stermektedir.

Bu skor modelin tahmin yeteneÄŸinin yÃ¼ksek olduÄŸunu ve klinik Ã¶n deÄŸerlendirmeler iÃ§in kullanÄ±labilir olduÄŸunu gÃ¶stermektedir.


---

## 7.4 Random Forest Classifier
"""

# Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 aÄŸaÃ§ ve sabit rastgele durum ile Random Forest sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± oluÅŸtur
rf_model.fit(X_train, y_train)  # Modeli eÄŸitim verileri (X_train, y_train) ile eÄŸit

# Predictions and evaluation
y_pred_rf = rf_model.predict(X_test)  # EÄŸitilmiÅŸ modeli kullanarak test verileri (X_test) Ã¼zerinde tahmin yap
print("Random Forest Classification Report:")  # Random Forest sÄ±nÄ±flandÄ±rma raporunu yazdÄ±r
print(classification_report(y_test, y_pred_rf))  # GerÃ§ek test etiketleri (y_test) ve tahmin edilen etiketler (y_pred_rf) kullanarak sÄ±nÄ±flandÄ±rma raporunu oluÅŸtur ve yazdÄ±r

# Confusion matrix for RF
cm_rf = confusion_matrix(y_test, y_pred_rf)  # GerÃ§ek ve tahmin edilen etiketler arasÄ±ndaki karÄ±ÅŸÄ±klÄ±k matrisini oluÅŸtur
sns.heatmap(cm_rf, annot=True, fmt="d", cmap='Greens')  # KarÄ±ÅŸÄ±klÄ±k matrisini bir Ä±sÄ± haritasÄ± olarak gÃ¶rselleÅŸtir (annot=True: deÄŸerleri gÃ¶ster, fmt="d": tam sayÄ± formatÄ±nda gÃ¶ster, cmap='Greens': yeÅŸil renk paleti kullan)
plt.title("Random Forest Confusion Matrix")  # GrafiÄŸe baÅŸlÄ±k ekle
plt.xlabel("Predicted")  # X eksenine "Tahmin Edilen" etiketini ekle
plt.ylabel("Actual")  # Y eksenine "GerÃ§ek" etiketini ekle
plt.show()  # GrafiÄŸi gÃ¶ster

# ROC Curve for RF
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]  # Test verileri iÃ§in sÄ±nÄ±f 1 olasÄ±lÄ±klarÄ±nÄ± al
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)  # GerÃ§ek etiketler ve olasÄ±lÄ±klar kullanarak ROC eÄŸrisi iÃ§in yanlÄ±ÅŸ pozitif oranÄ± (fpr), gerÃ§ek pozitif oranÄ± (tpr) ve eÅŸikleri hesapla
roc_auc_rf = auc(fpr_rf, tpr_rf)  # AUC (EÄŸri AltÄ±ndaki Alan) deÄŸerini hesapla
plt.figure(figsize=(8, 6))  # Yeni bir figÃ¼r oluÅŸtur
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest ROC curve (AUC = {roc_auc_rf:.2f})', color='green')  # ROC eÄŸrisini Ã§iz ve AUC deÄŸerini etikete ekle
plt.plot([0, 1], [0, 1], 'k--')  # Rastgele tahmin Ã§izgisini (45 derece) Ã§iz
plt.xlabel('False Positive Rate')  # X eksenine "YanlÄ±ÅŸ Pozitif OranÄ±" etiketini ekle
plt.ylabel('True Positive Rate')  # Y eksenine "GerÃ§ek Pozitif OranÄ±" etiketini ekle
plt.title('ROC Curve - Random Forest')  # GrafiÄŸe baÅŸlÄ±k ekle
plt.legend(loc="lower right")  # Legendi saÄŸ alt kÃ¶ÅŸeye yerleÅŸtir
plt.show()  # GrafiÄŸi gÃ¶ster

joblib.dump(rf_model, "random_forest_model.pkl")
joblib.dump(X_train.columns.tolist(), "random_forest_model_feature_names.pkl")

"""---
# ğŸ“Œ Random Forest Confusion Matrix HakkÄ±nda Yorum:

Random Forest modeli, depresyonlu bireyleri yÃ¼ksek baÅŸarÄ±yla tespit etmiÅŸtir (recall â‰ˆ %81.2).

Bununla birlikte, 787 saÄŸlÄ±klÄ± birey yanlÄ±ÅŸ ÅŸekilde depresyonlu olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r.

Bu durum modelin pozitif sÄ±nÄ±fÄ± fazla tahmin etme eÄŸiliminde olduÄŸunu, ancak depresyonlu bireyleri kaÃ§Ä±rma oranÄ±nÄ±n dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶stermektedir.

Modelin genel doÄŸruluÄŸu yaklaÅŸÄ±k %74.9â€™dur.

---



# ğŸ“Œ ROC Curve - Random Forest HakkÄ±nda Yorum:

ROC eÄŸrisi modelin depresyonlu bireyleri depresyonsuzlardan ayÄ±rt etme becerisinin yÃ¼ksek olduÄŸunu gÃ¶stermektedir.

AUC deÄŸeri olan 0.81, modelin tahmin baÅŸarÄ±sÄ±nÄ±n rastgele seÃ§imden Ã§ok daha Ã¼stÃ¼n olduÄŸunu ve pozitif sÄ±nÄ±fÄ± ayÄ±rt etme kapasitesinin oldukÃ§a tatmin edici olduÄŸunu ortaya koymaktadÄ±r.


---

## 7.5 KNN Classifier
"""

# KNN (K-En YakÄ±n KomÅŸu) sÄ±nÄ±flandÄ±rÄ±cÄ± modelini oluÅŸtur (komÅŸu sayÄ±sÄ± 18 olarak ayarlandÄ±)
knn_model = KNeighborsClassifier(n_neighbors=18)

# Modeli eÄŸitim verisi ile eÄŸit
knn_model.fit(X_train, y_train)

# Test verileri Ã¼zerinde tahmin yap
y_pred_knn = knn_model.predict(X_test)

# KNN sÄ±nÄ±flandÄ±rma performans raporunu yazdÄ±r
print("KNN Sklearn Classification Report:")
print(classification_report(y_test, y_pred_knn))

# KarÄ±ÅŸÄ±klÄ±k matrisi oluÅŸtur ve gÃ¶rselleÅŸtir
cm_knn = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(cm_knn, annot=True, fmt="d", cmap='Blues')
plt.title("KNN KarÄ±ÅŸÄ±klÄ±k Matrisi")
plt.xlabel("Tahmin Edilen")
plt.ylabel("GerÃ§ek")
plt.show()

# ROC eÄŸrisi iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ± al (pozitif sÄ±nÄ±f iÃ§in)
y_prob_knn = knn_model.predict_proba(X_test)[:, 1]

# ROC eÄŸrisi metriklerini hesapla
fpr, tpr, thresholds = roc_curve(y_test, y_prob_knn)
roc_auc_knn = auc(fpr, tpr)

# ROC eÄŸrisini Ã§iz
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'KNN ROC EÄŸrisi (AUC = {roc_auc_knn:.2f})', color='darkorange')
plt.plot([0,1], [0,1], 'k--')  # Rastgele sÄ±nÄ±flandÄ±rma Ã§izgisi
plt.xlabel('YanlÄ±ÅŸ Pozitif OranÄ±')
plt.ylabel('DoÄŸru Pozitif OranÄ±')
plt.title('ROC EÄŸrisi - KNN')
plt.legend(loc="lower right")
plt.show()

# Modeli ve kullandÄ±ÄŸÄ± Ã¶zellik isimlerini .pkl dosyasÄ± olarak kaydet
joblib.dump(knn_model, "knn_model.pkl")
joblib.dump(X_train.columns.tolist(), "knn_model_feature_names.pkl")

"""---
# ğŸ“Œ KNN Confusion Matrix HakkÄ±nda Yorum:

KNN modelinin oluÅŸturduÄŸu karÄ±ÅŸÄ±klÄ±k matrisi, modelin depresyon var (1) sÄ±nÄ±fÄ±nÄ± belirlemede gÃ¼Ã§lÃ¼ olduÄŸunu gÃ¶stermektedir.

Toplamda 2649 doÄŸru pozitif tahmin yapÄ±lÄ±rken, sadece 589 depresyonlu birey gÃ¶zden kaÃ§Ä±rÄ±lmÄ±ÅŸtÄ±r. Ancak 742 saÄŸlÄ±klÄ± birey yanlÄ±ÅŸ ÅŸekilde depresyonlu olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r.

Bu modelin bazÄ± durumlarda fazla uyarÄ±cÄ± olabileceÄŸini ancak depresyonu kaÃ§Ä±rma oranÄ±nÄ±n dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶stermektedir.

---



# ğŸ“Œ ROC Curve - KNN HakkÄ±nda Yorum:
ROC eÄŸrisi modelin depresyonlu ve depresyonsuz bireyleri ayÄ±rt etme yeteneÄŸini Ã¶lÃ§mektedir.

AUC = 0.82 olmasÄ± KNN modelinin sÄ±nÄ±flarÄ± ayÄ±rt etme becerisinin oldukÃ§a baÅŸarÄ±lÄ± olduÄŸunu gÃ¶stermektedir.

Bu skor modelin rastgele tahminden Ã§ok daha iyi bir performans sergilediÄŸini ve gerÃ§ek pozitif oranÄ±nÄ± yÃ¼ksek tutarken yanlÄ±ÅŸ pozitif oranÄ±nÄ± dengeli tuttuÄŸunu ortaya koymaktadÄ±r.



---

## 7.6 Decision Tree Classifier
"""

# ğŸ¯ Decision Tree Modeli
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

# ğŸ”® Tahmin
y_pred_dt = dt_model.predict(X_test)
print("Decision Tree Sklearn Classification Report:")
print(classification_report(y_test, y_pred_dt))

# ğŸ“Š Confusion Matrix
cm_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm_dt, annot=True, fmt="d", cmap='Greens')
plt.title("Decision Tree Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ğŸ“ˆ ROC Curve
y_prob_dt = dt_model.predict_proba(X_test)[:, 1]
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)
roc_auc_dt = auc(fpr_dt, tpr_dt)
plt.figure(figsize=(8,6))
plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree ROC curve (AUC = {roc_auc_dt:.2f})', color='darkgreen')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Decision Tree')
plt.legend(loc="lower right")
plt.show()

# ğŸ’¾ Modeli ve Ã¶zellik isimlerini kaydet
joblib.dump(dt_model, "decision_tree_model.pkl")
joblib.dump(X_train.columns.tolist(), "decision_tree_feature_names.pkl")

"""---
# ğŸ“Œ Decision Tree Confusion Matrix HakkÄ±nda Yorum:

Decision Tree modeli depresyonu tespit etme konusunda sÄ±nÄ±rlÄ± baÅŸarÄ± gÃ¶stermiÅŸtir.

Modelin doÄŸruluÄŸu %67.8 olup, bu oran diÄŸer modellere kÄ±yasla daha dÃ¼ÅŸÃ¼ktÃ¼r. Hem yanlÄ±ÅŸ pozitif (937 kiÅŸi) hem de yanlÄ±ÅŸ negatif (875 kiÅŸi) sayÄ±sÄ± oldukÃ§a yÃ¼ksektir.

Bu da modelin sÄ±nÄ±flar arasÄ±nda ayrÄ±m yapmada kararsÄ±z kaldÄ±ÄŸÄ±nÄ± ve aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) riskinin yÃ¼ksek olduÄŸunu gÃ¶sterir.

---



# ğŸ“Œ ROC Curve - Decision Tree HakkÄ±nda Yorum:
ROC eÄŸrisi modelin depresyonlu bireyleri depresyonsuzlardan ayÄ±rt etme yeteneÄŸinin oldukÃ§a zayÄ±f olduÄŸunu gÃ¶steriyor.

AUC = 0.67 deÄŸeri modelin ayÄ±rt edici gÃ¼cÃ¼nÃ¼n zayÄ±f olduÄŸunu ve daha geliÅŸmiÅŸ modellerin tercih edilmesi gerektiÄŸini ortaya koyuyor.



---

## 7.6 Hybrid Random Forest + XGBoost Hybrid Classifier
"""

# Random Forest + XGBoost Hibrit Modeli

# ğŸ”¹ Random Forest Modelini EÄŸit
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# ğŸ” Random Forest'tan Ã¶zellik Ã¶nem dÃ¼zeylerini al
feature_importances = rf_model.feature_importances_

# ğŸ”§ Ã–nemli Ã¶zellikleri seÃ§ (Ã¶nemi %1'den bÃ¼yÃ¼k olanlar)
important_features = X_train.columns[feature_importances > 0.01]
X_train_selected = X_train[important_features]
X_test_selected = X_test[important_features]

# ğŸ”¹ XGBoost Modelini, seÃ§ilen Ã¶zelliklerle eÄŸit
xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.2, max_depth=3, eval_metric='logloss')
xgb_model.fit(X_train_selected, y_train)

# ğŸ“Š Tahminleri yap
y_pred4 = xgb_model.predict(X_test_selected)

# ğŸ“‹ Modeli deÄŸerlendir: KarÄ±ÅŸÄ±klÄ±k Matrisi ve SÄ±nÄ±flandÄ±rma Raporu
conf_matrix_rf_XGB = confusion_matrix(y_test, y_pred4)
class_report_rf_XGB = classification_report(y_test, y_pred4)

# ğŸ¨ KarÄ±ÅŸÄ±klÄ±k matrisini gÃ¶rselleÅŸtir
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_rf_XGB, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Depresyon Yok', 'Depresyon Var'],
            yticklabels=['Depresyon Yok', 'Depresyon Var'])
plt.xlabel('Tahmin Edilen Etiket')
plt.ylabel('GerÃ§ek Etiket')
plt.title('KarÄ±ÅŸÄ±klÄ±k Matrisi - Random Forest + XGBoost Hibrit Modeli')
plt.show()

# ğŸ” ROC EÄŸrisi iÃ§in pozitif sÄ±nÄ±fa ait olasÄ±lÄ±k tahminlerini al
y_prob4 = xgb_model.predict_proba(X_test_selected)[:, 1]

# ğŸ“ˆ ROC eÄŸrisi metriklerini hesapla
fpr, tpr, thresholds = roc_curve(y_test, y_prob4)
roc_auc = auc(fpr, tpr)

# ğŸ¯ ROC eÄŸrisini Ã§iz
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkgreen', lw=2,
         label=f'ROC EÄŸrisi - Hybrid RF + XGBoost (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')  # Rastgele tahmin Ã§izgisi
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('YanlÄ±ÅŸ Pozitif OranÄ±')
plt.ylabel('DoÄŸru Pozitif OranÄ±')
plt.title('ROC EÄŸrisi - Hibrit Model (RF + XGBoost)')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# ğŸ–¨ï¸ SÄ±nÄ±flandÄ±rma raporunu yazdÄ±r
print("SÄ±nÄ±flandÄ±rma Raporu:\n", class_report_rf_XGB)

# ğŸ’¾ Modeli ve seÃ§ilen Ã¶zellik isimlerini .pkl dosyasÄ±na kaydet
joblib.dump(xgb_model, "random_forest_with_xgboost_model.pkl")
joblib.dump(important_features.tolist(), "random_forest_with_xgboost_model_names.pkl")

"""---
# ğŸ“Œ RF + XGBoost (Hybrid) Confusion Matrix HakkÄ±nda Yorum:

Bu hibrit model depresyonlu bireyleri tespit etme aÃ§Ä±sÄ±ndan oldukÃ§a baÅŸarÄ±lÄ±dÄ±r (Recall â‰ˆ %83.9).

AyrÄ±ca doÄŸruluk oranÄ± %77.1 ile diÄŸer klasik modellerin Ã¼zerinde seyretmektedir. YanlÄ±ÅŸ negatif sayÄ±sÄ± 522 ile dÃ¼ÅŸÃ¼k kalmÄ±ÅŸtÄ±r, bu da depresyonu gÃ¶zden kaÃ§Ä±rma riskini en aza indirir.

Precision deÄŸeri de oldukÃ§a dengeli ve yÃ¼ksek olup yanlÄ±ÅŸ alarmlarÄ±n da makul dÃ¼zeyde olduÄŸunu gÃ¶sterir.

---



# ğŸ“Œ ROC Curve - RF + XGBoost (Hybrid) HakkÄ±nda Yorum:
ROC eÄŸrisi modelin doÄŸru pozitif oranÄ±nÄ± yÃ¼ksek tutarken yanlÄ±ÅŸ pozitif oranÄ±nÄ± kontrol altÄ±nda tuttuÄŸunu gÃ¶steriyor.

AUC deÄŸeri olan 0.84, sÄ±nÄ±flar arasÄ±nda gÃ¼Ã§lÃ¼ bir ayÄ±rt etme yeteneÄŸine iÅŸaret eder. ROC eÄŸrisinin eÄŸimi yÃ¼ksek bu da modelin gÃ¼venilirliÄŸini artÄ±rÄ±r.



---

# 7.7 Modellerin Skor KarÅŸÄ±laÅŸtÄ±rmasÄ±
"""

# ğŸ” Modellerin F1 ve AUC skorlarÄ±nÄ± iÃ§eren tabloyu oluÅŸtur
model_scores = pd.DataFrame({
    "Model": [
        "Logistic Regression",
        "KNN",
        "Random Forest",
        "Decision Tree",
        "Hybrid RF + XGBoost"
    ],
    "F1 Score": [0.77, 0.75, 0.76, 0.68, 0.77],
    "AUC": [0.84, 0.82, 0.81, 0.67, 0.84]
})

# ğŸ”¢ Model sÃ¼tununu indeks olarak ayarla ve Ã§ubuk grafik Ã§iz
ax = model_scores.set_index("Model").plot(kind="bar", figsize=(10, 6), colormap="Set2")

# ğŸ¨ Grafik baÅŸlÄ±ÄŸÄ± ve eksen etiketleri
plt.title("Makine Ã–ÄŸrenmesi Modellerinin Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
plt.ylabel("Skor")
plt.xlabel("Model")
plt.xticks(rotation=45)
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

# ğŸ·ï¸ Her Ã§ubuÄŸun Ã¼stÃ¼ne skor deÄŸerini yazdÄ±r
for container in ax.containers:
    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)

# ğŸ“Š GrafiÄŸi gÃ¶ster
plt.tight_layout()
plt.show()

"""# AdÄ±m 8: Streamlit ile EtkileÅŸimli ArayÃ¼z OluÅŸturma"""

!pip install streamlit pyngrok --quiet

!ngrok config add-authtoken 2M9KBRy3QTJS3XDjwUmBjAyRZFG_3hmsrrRZrFF8CpELToR4d

!pip install -q streamlit pyngrok

!streamlit run app.py &>/dev/null &

from pyngrok import ngrok

# Streamlit sunucusu Ã§alÄ±ÅŸtÄ±rÄ±lacak port
port = 8501

# Elle http tÃ¼neli baÅŸlat (yeni yÃ¶nteme uyumlu)
public_url = ngrok.connect(addr=f"http://localhost:{port}")
print("ğŸ”— UygulamayÄ± aÃ§:", public_url)